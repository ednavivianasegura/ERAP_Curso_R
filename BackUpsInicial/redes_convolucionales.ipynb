{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ednavivianasegura/ERAP_Curso_R/blob/main/BackUpsInicial/redes_convolucionales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autores:** Edna Viviana Segura Alvarado - Hans Mauricio Carrillo Hernández\n",
        "\n",
        "**Institución:** Universidad de la Rioja\n",
        "\n",
        "**Fecha:** Junio/2025\n",
        "\n",
        "**Clasificación de Imágenes con Redes Neuronales Convolucionales**\n",
        "\n",
        "Las redes neuronales convolucionales son conocidas habitualmente por sus siglas en inglés, CNNs (Convolutional Neural Networks).\n"
      ],
      "metadata": {
        "id": "df4SwpVU5rnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías\n",
        "\n",
        "Verificación versión de TensorFlow"
      ],
      "metadata": {
        "id": "-H9QnSsW6T64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "0OgmnU6r6Y2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los imágenes a clasificar son tomadas de:\n",
        "\n",
        "Julien de la Bruère-Terreault, conjunto de datos \"Rock-Paper-Scissors Images\", disponible bajo la licencia CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0/) en https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors"
      ],
      "metadata": {
        "id": "QOGktUrjGHeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonar repositorio\n",
        "!git clone https://github.com/ednavivianasegura/ERAP_CursoPython/\n",
        "os.chdir(\"/content/ERAP_CursoPython/Modulo2_Fundamentos_AI\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gElhheaSmMbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga el dataset \"rockpaperscissors\" del usuario \"drgfreeman\" usando Kaggle Hub\n",
        "# Retorna la ruta donde se guardó el dataset descargado\n",
        "path = kagglehub.dataset_download(\"drgfreeman/rockpaperscissors\")\n",
        "\n",
        "# Lista todos los archivos y directorios contenidos en la ruta de descarga\n",
        "# os.listdir() devuelve una lista con los nombres de las entradas en el directorio\n",
        "contenido = os.listdir(path)\n",
        "\n",
        "# Notas importantes:\n",
        "# 1. kagglehub.dataset_download() descarga el dataset en un formato específico de Kaggle\n",
        "# 2. El dataset puede venir en diferentes estructuras:\n",
        "#    - Como directorio con subdirectorios (rock/, paper/, scissors/)\n",
        "#    - Como archivo comprimido (dataset.zip)\n",
        "# 3. Si os.listdir() falla, puede ser porque:\n",
        "#    - La descarga no se completó correctamente\n",
        "#    - El path retornado no es un directorio directamente accesible\n",
        "#    - Se necesitan permisos adicionales\n",
        "\n"
      ],
      "metadata": {
        "id": "8jfaPe41vUXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime el número de archivos en el directorio 'rock'\n",
        "print(len(os.listdir(path + \"/\" + \"rock\")))  # Muestra cuántas imágenes de 'rock' hay disponibles\n",
        "\n",
        "# Imprime el número de archivos en el directorio 'paper'\n",
        "print(len(os.listdir(path + \"/\" + \"paper\")))  # Muestra cuántas imágenes de 'paper' hay disponibles\n",
        "\n",
        "# Lista TODOS los archivos en el directorio 'scissors' (puede ser mucha salida)\n",
        "print(os.listdir(path + \"/\" + \"scissors\"))  # Muestra los nombres de todos los archivos de 'scissors'"
      ],
      "metadata": {
        "id": "M3w05VDtxSpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar Imágenes del repositorio:\n",
        "\n",
        "Se considera que las imágenes están organizadas por categoría, almacenadas en directorios separados llamados *rock*, *paper* y *scissors*. Dentro de cada uno, los archivos de imagen están nombrados secuencialmente desde 0.png hasta 699.png, representando su número correspondiente.\n"
      ],
      "metadata": {
        "id": "NBP388Qk6PVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descripción de clases y su identificador\n",
        "descripcion = (\"paper\", \"rock\", \"scissors\")\n",
        "clases = {\"paper\": 0, \"rock\": 1, \"scissors\": 2}\n",
        "\n",
        "# Número de imágenes de cada clase a considerar (máximo 700)\n",
        "num_img_clase = 700\n",
        "\n",
        "# Porcentajes de división\n",
        "train_ratio = 0.7\n",
        "test_ratio = 0.3\n",
        "\n",
        "# Calcular número de imágenes para entrenamiento y prueba\n",
        "num_entrena = round(num_img_clase * train_ratio)\n",
        "num_prueba = round(num_img_clase * test_ratio)\n",
        "\n",
        "# Inicializar arrays para almacenar los datos\n",
        "imagenes_entrena = np.empty((num_entrena * len(clases), 200, 300, 3), dtype=\"uint8\")\n",
        "clases_entrena = np.empty(num_entrena * len(clases), dtype=\"uint8\")\n",
        "\n",
        "imagenes_prueba = np.empty((num_prueba * len(clases), 200, 300, 3), dtype=\"uint8\")\n",
        "clases_prueba = np.empty(num_prueba * len(clases), dtype=\"uint8\")\n",
        "\n",
        "# Para cada clase, seleccionar 700 imágenes aleatorias y dividirlas en train/test\n",
        "for clase in clases:\n",
        "    # Obtener lista de todos los archivos en el directorio de la clase\n",
        "    archivos = os.listdir(path + \"/\" + clase)\n",
        "\n",
        "    # Seleccionar aleatoriamente 700 imágenes (sin repetición)\n",
        "    archivos_seleccionados = random.sample(archivos, num_img_clase)\n",
        "\n",
        "    # Dividir en conjuntos de entrenamiento y prueba\n",
        "    archivos_train = archivos_seleccionados[:num_entrena]\n",
        "    archivos_test = archivos_seleccionados[num_entrena:num_img_clase]\n",
        "\n",
        "    # Cargar imágenes de entrenamiento\n",
        "    for i, archivo in enumerate(archivos_train):\n",
        "        imagen = Image.open(os.path.join(path, clase, archivo))\n",
        "        indice = i + clases[clase] * num_entrena\n",
        "        imagenes_entrena[indice] = np.array(imagen)\n",
        "        clases_entrena[indice] = clases[clase]\n",
        "\n",
        "    # Cargar imágenes de prueba\n",
        "    for i, archivo in enumerate(archivos_test):\n",
        "        imagen = Image.open(os.path.join(path, clase, archivo))\n",
        "        indice = i + clases[clase] * num_prueba\n",
        "        imagenes_prueba[indice] = np.array(imagen)\n",
        "        clases_prueba[indice] = clases[clase]\n",
        "\n",
        "# Verificación\n",
        "print(f\"Total imágenes entrenamiento: {len(imagenes_entrena)}\")\n",
        "print(f\"Total imágenes prueba: {len(imagenes_prueba)}\")\n",
        "print(\"¡Datos cargados exitosamente!\")"
      ],
      "metadata": {
        "id": "urQdkT1Tzexq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualización de imágenes aleatorias"
      ],
      "metadata": {
        "id": "-D03FsJt9Hgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una figura de matplotlib con tamaño 10x10 pulgadas\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Mostrar 100 imágenes en una cuadrícula de 10x10\n",
        "for i in range(100):\n",
        "    # Crear subplot en posición i+1 (comienza en 1, no en 0)\n",
        "    plt.subplot(10, 10, i + 1)\n",
        "\n",
        "    # Seleccionar un índice aleatorio dentro del rango de imágenes de entrenamiento\n",
        "    indice = random.randint(0, num_entrena*len(clases) - 1)\n",
        "\n",
        "    # Mostrar la imagen correspondiente al índice seleccionado\n",
        "    # Se usa cmap=\"gray\" para mostrar en escala de grises (aunque las imágenes son RGB)\n",
        "    plt.imshow(imagenes_entrena[indice], cmap=\"gray\")\n",
        "\n",
        "    # Añadir etiqueta (clase) como texto en la parte inferior\n",
        "    plt.xlabel(descripcion[clases_entrena[indice]])\n",
        "\n",
        "    # Configuraciones de estilo para mejorar la visualización:\n",
        "    plt.grid(False)    # Desactivar cuadrícula\n",
        "    plt.box(False)     # Desactivar borde alrededor de la imagen\n",
        "    plt.xticks([])     # Eliminar marcas del eje X\n",
        "    plt.yticks([])     # Eliminar marcas del eje Y\n",
        "\n",
        "# Mostrar la figura completa con todas las sub-imágenes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CGuDUltr9IX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de una sola imagen en tamaño grande"
      ],
      "metadata": {
        "id": "GjJSUv12K9Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_aleatorio = random.randint(0, num_entrena*len(clases) - 1)\n",
        "# Crear una nueva figura de matplotlib (tamaño por defecto)\n",
        "plt.figure()\n",
        "\n",
        "# Mostrar la imagen de prueba número aleatorio del conjunto de datos\n",
        "plt.imshow(imagenes_prueba[num_aleatorio])  # Muestra la imagen con mapeo de colores automático\n",
        "\n",
        "# Añadir una barra de color (colorbar) que indica la escala de valores de píxeles\n",
        "plt.colorbar()  # Útil para entender el rango de valores de intensidad en la imagen\n",
        "\n",
        "# Configuraciones de estilo para una visualización más limpia:\n",
        "plt.grid(False)    # Desactivar la cuadrícula (repetido por seguridad)\n",
        "plt.box(False)     # Desactivar el borde alrededor de la imagen\n",
        "plt.grid(False)    # Desactivar la cuadrícula nuevamente (redundante pero inofensivo)\n",
        "plt.xticks([])     # Eliminar las marcas y etiquetas del eje X\n",
        "plt.yticks([])     # Eliminar las marcas y etiquetas del eje Y\n",
        "\n",
        "# Mostrar la figura con la imagen y la barra de color\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQiov_a85ap2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Escalar los píxeles de las imágenes del rango [0, 255] al rango [0, 1]\n",
        "imagenes_entrena = imagenes_entrena / 255\n",
        "imagenes_prueba = imagenes_prueba / 255"
      ],
      "metadata": {
        "id": "B-KOQDFw5yIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo CNN para Clasificación de Imágenes"
      ],
      "metadata": {
        "id": "wZqC92qm9BtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición del modelo secuencial (capas apiladas linealmente)\n",
        "modelo = tf.keras.Sequential([\n",
        "    # Primera capa convolucional:\n",
        "    # - 32 filtros de 3x3 píxeles\n",
        "    # - Función de activación ReLU (Rectified Linear Unit)\n",
        "    # - Input shape: 200 (alto) x 300 (ancho) x 3 canales (RGB)\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 300, 3)),\n",
        "\n",
        "    # Capa de Max Pooling:\n",
        "    # - Reducción dimensional con ventana de 2x2\n",
        "    # - Reduce el tamaño espacial a la mitad (selecciona el valor máximo en cada ventana)\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Segunda capa convolucional:\n",
        "    # - 64 filtros de 3x3 píxeles\n",
        "    # - Función de activación ReLU\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Segunda capa de Max Pooling:\n",
        "    # - Nueva reducción dimensional 2x2\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Capa Flatten:\n",
        "    # - \"Aplana\" los mapas de características 2D a un vector 1D\n",
        "    # - Prepara los datos para las capas densas (fully connected)\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Capa Densa (fully connected):\n",
        "    # - 64 neuronas con activación ReLU\n",
        "    # - Capa intermedia para aprendizaje de características complejas\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "\n",
        "    # Capa de Salida:\n",
        "    # - 3 neuronas (una por cada clase: paper, rock, scissors)\n",
        "    # - Sin función de activación (logits)\n",
        "    tf.keras.layers.Dense(3),\n",
        "\n",
        "    # Capa Softmax:\n",
        "    # - Convierte los logits en probabilidades (suma = 1)\n",
        "    # - Cada neurona representa la probabilidad de pertenecer a cada clase\n",
        "    tf.keras.layers.Softmax()\n",
        "])"
      ],
      "metadata": {
        "id": "FBXehGP654RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cofigurarción del Modelo para Entrenamiento"
      ],
      "metadata": {
        "id": "dKcUWbNgEaUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(\n",
        "    # Optimizador: Descenso de Gradiente Estocástico (SGD)\n",
        "    # - Algoritmo de optimización básico que actualiza los pesos en dirección opuesta al gradiente\n",
        "    # - Versión por defecto sin ajuste de learning rate (puede no ser óptimo)\n",
        "    optimizer=\"sgd\",  # Equivalente a tf.keras.optimizers.SGD()\n",
        "\n",
        "    # Función de pérdida: Sparse Categorical Crossentropy\n",
        "    # - Adecuada para clasificación multi-clase con etiquetas enteras (0, 1, 2)\n",
        "    # - Calcula la diferencia entre probabilidades predichas y etiquetas reales\n",
        "    # - \"Sparse\" significa que acepta etiquetas enteras directamente (no requiere one-hot encoding)\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "\n",
        "    # Métrica a monitorear: Precisión (Accuracy)\n",
        "    # - Porcentaje de predicciones correctas sobre el total\n",
        "    # - Útil para problemas balanceados como rock-paper-scissors\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "k0FU86yC59hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento de la CNN"
      ],
      "metadata": {
        "id": "Ls3zIAGQFUgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrena la red neuronal con las imágenes y clases del conjunto de entrenamiento.\n",
        "# El proceso se repite durante 10 épocas, es decir, el modelo verá todo el conjunto de datos 10 veces.\n",
        "modelo.fit(imagenes_entrena, clases_entrena, epochs=10)\n"
      ],
      "metadata": {
        "id": "u72nLupI6CQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación del modelo"
      ],
      "metadata": {
        "id": "Jr0K2DTuFctt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalúa el rendimiento del modelo sobre el conjunto de prueba (imágenes y etiquetas reales)\n",
        "# Retorna la pérdida (loss) y la exactitud (accuracy)\n",
        "perdida, exactitud = modelo.evaluate(imagenes_prueba, clases_prueba)\n",
        "\n",
        "# Imprime la pérdida obtenida en el conjunto de prueba\n",
        "print(f\"Pérdida (Loss) en el conjunto de prueba: {perdida:.4f}\")\n",
        "\n",
        "# Imprime la exactitud obtenida, que representa el porcentaje de imágenes clasificadas correctamente\n",
        "print(\"Exactitud (Accuracy) = aciertos_prueba / imagenes_de_prueba:\", exactitud)\n",
        "\n",
        "# Imprime la exactitud como porcentaje con dos decimales\n",
        "print(f\"Exactitud (Accuracy) en el conjunto de prueba: {exactitud * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "bzlGmvCgI6uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación de las Imágenes del conjunto de prueba con la CNN entrenada"
      ],
      "metadata": {
        "id": "OEJUw89HG9K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Genera predicciones del modelo para las imágenes del conjunto de prueba\n",
        "# El resultado será un array con las probabilidades asignadas a cada clase para cada imagen\n",
        "predicciones = modelo.predict(imagenes_prueba)\n"
      ],
      "metadata": {
        "id": "pM1mSUYW6ook"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salida de la CNN para cada imagen del conjunto de prueba"
      ],
      "metadata": {
        "id": "DBZLnGIiHOhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea un arreglo vacío para almacenar la clase predicha de cada imagen del conjunto de prueba\n",
        "# El tamaño del arreglo es igual al número total de imágenes de prueba (num_prueba * número de clases)\n",
        "clase_predicha = np.empty(num_prueba * len(clases), dtype=\"uint8\")\n",
        "\n",
        "# Recorre cada instancia (imagen) del conjunto de prueba\n",
        "for instancia in range(num_prueba * len(clases)):\n",
        "    # Obtiene la clase predicha: índice de la mayor probabilidad en las predicciones de esa imagen\n",
        "    clase_predicha[instancia] = np.argmax(predicciones[instancia])\n",
        "\n",
        "    # Compara la clase predicha con la clase verdadera\n",
        "    if clase_predicha[instancia] == clases_prueba[instancia]:\n",
        "        print(\"Probabilidades:\", predicciones[instancia],\n",
        "              \"Clase predicha:\", clase_predicha[instancia],\n",
        "              \"Clase correcta:\", clases_prueba[instancia],\n",
        "              \"La Red Neuronal ACERTÓ\")\n",
        "    else:\n",
        "        print(\"Probabilidades:\", predicciones[instancia],\n",
        "              \"Clase predicha:\", clase_predicha[instancia],\n",
        "              \"Clase correcta:\", clases_prueba[instancia],\n",
        "              \"La Red Neuronal ERRÓ\")\n"
      ],
      "metadata": {
        "id": "ZHbJgcEH6zJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultado de la evaluación: matriz de confusión:"
      ],
      "metadata": {
        "id": "LvITyWvzHjsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignación de etiquetas numéricas para cada clase: papel = 0, piedra = 1, tijera = 2\n",
        "# Genera la matriz de confusión comparando etiquetas reales con predichas\n",
        "matriz = tf.math.confusion_matrix(clases_prueba, clase_predicha)\n",
        "\n",
        "# Imprime la matriz de confusión como array de NumPy\n",
        "print(\"Matriz de Confusión:\\n\", matriz.numpy())\n",
        "\n",
        "# Define etiquetas de clase\n",
        "etiquetas = ['Papel', 'Piedra', 'Tijera']\n",
        "\n",
        "# Convierte la matriz de confusión a un array de NumPy (por si está en formato Tensor)\n",
        "matriz_np = matriz.numpy()\n",
        "\n",
        "# Configura el tamaño de la figura\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "# Dibuja la matriz de confusión como un mapa de calor\n",
        "sns.heatmap(matriz_np, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=etiquetas, yticklabels=etiquetas)\n",
        "\n",
        "# Títulos y etiquetas\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.xlabel(\"Clase Predicha\")\n",
        "plt.ylabel(\"Clase Verdadera\")\n",
        "\n",
        "# Muestra la figura\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PMrUkZMR8040"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}